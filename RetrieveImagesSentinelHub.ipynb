{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentinel Hub - Fetch images for fields\n",
    "\n",
    "https://docs.sentinel-hub.com/api/latest/user-guides/beginners-guide/#python\n",
    "\n",
    "\n",
    "https://sentinelhub-py.readthedocs.io/en/latest/examples/process_request.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from oauthlib.oauth2 import BackendApplicationClient\n",
    "from requests_oauthlib import OAuth2Session\n",
    "from PIL import Image\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import datetime as dt\n",
    "from math import ceil\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from sentinelhub import (SHConfig, \n",
    "                        SentinelHubCatalog, \n",
    "                        BBox, \n",
    "                        CRS, \n",
    "                        DataCollection, \n",
    "                        Geometry, \n",
    "                        filter_times, \n",
    "                        SentinelHubRequest, \n",
    "                        MimeType, \n",
    "                        SentinelHubDownloadClient)\n",
    "\n",
    "# The following is not a package. It is a file utils.py which should be in the same folder as this notebook.\n",
    "from utils import plot_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Read in the Catch Crop fields\n",
    "# =============================================================================\n",
    "\n",
    "# Path to GeoJSON\n",
    "path_to_file = \"Data/ccInfoGDF.geojson\"\n",
    "path_to_file = \"C:/Users/morte/OneDrive - Syddansk Universitet/Speciale2023/Data/ccInfoGDF.geojson\" # GeoJSON med alle typer efterafgrøder\n",
    "path_to_file = f'D:/data/CatchCrop/ccInfoGDF.geojson' # GeoJSON med alle typer efterafgrøder\n",
    "# path_to_file = \"C:/Users/morte/OneDrive - Syddansk Universitet/Speciale2023/Data/ccNoAltInfoGDF.geojson\" # GeoJSON kun med Målrettede Efterafgrøder\n",
    "\n",
    "# Read in GeoJSON\n",
    "with open(path_to_file, encoding='utf-8') as f:\n",
    "    ccData = json.load(f)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Sentinel Hub\n",
    "# =============================================================================\n",
    "\n",
    "# Creates configuration file for SentinelHub service\n",
    "config = SHConfig()\n",
    "\n",
    "# Saves Client ID and Secret to configuration\n",
    "# Credentials should be submitted in the follwong objects:\n",
    "config.sh_client_id = '' \n",
    "config.sh_client_secret = ''\n",
    "\n",
    "# Creates a catalog of Sentinel Hub services\n",
    "catalog = SentinelHubCatalog(config=config)\n",
    "\n",
    "collection_id = \"sentinel-2-l2a\"\n",
    "\n",
    "# evalscript\n",
    "evalscriptRGB = \"\"\"\n",
    "//VERSION=3\n",
    "\n",
    "function setup() {\n",
    "    return {\n",
    "        input: [{\n",
    "            bands: [\"B04\", \"B03\", \"B02\"],\n",
    "            units: \"REFLECTANCE\" // default units\n",
    "        }],\n",
    "        output: { \n",
    "            id: 'default',\n",
    "            bands: 3,\n",
    "            sampleType: \"AUTO\" // default value - scales the output values from [0,1] to [0,255].\n",
    "        }\n",
    "    };\n",
    "}\n",
    "\n",
    "function evaluatePixel(sample) {\n",
    "  return [sample.B02, \n",
    "          sample.B03, \n",
    "          sample.B04];\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "evalscriptAllBands_L2A = \"\"\"\n",
    "    //VERSION=3\n",
    "    function setup() {\n",
    "        return {\n",
    "            input: [{\n",
    "                bands: [\"B02\",\"B03\",\"B04\",\"B08\",\"B8A\",\"B11\",\"B12\",\"CLP\", \"CLM\"],\n",
    "                units: \"DN\"\n",
    "            }],\n",
    "            output: {\n",
    "                bands: 9,\n",
    "                sampleType: \"INT16\"\n",
    "            }\n",
    "        };\n",
    "    }\n",
    "\n",
    "    function evaluatePixel(sample) {\n",
    "        return [sample.B02,\n",
    "                sample.B03,\n",
    "                sample.B04,\n",
    "                sample.B08,\n",
    "                sample.B8A,\n",
    "                sample.B11,\n",
    "                sample.B12,\n",
    "                sample.CLP,\n",
    "                sample.CLM];\n",
    "    }\n",
    "\"\"\"\n",
    "# Band selection\n",
    "# https://gisgeography.com/sentinel-2-bands-combinations/\n",
    "\n",
    "# Color Infrared (B8, B4, B3)\n",
    "# Sentinel 2 Color Infrared\n",
    "# The color infrared band combination is meant to emphasize healthy and unhealthy vegetation. By using the near-infrared (B8) band, it’s especially good at reflecting chlorophyll. \n",
    "# This is why in a color infrared image, denser vegetation is red. But urban areas are white.\n",
    "\n",
    "# Short-Wave Infrared (B12, B8A, B4)\n",
    "# Sentinel 2 Shortwave Infrared\n",
    "# The short-wave infrared band combination uses SWIR (B12), NIR (B8A), and red (B4). This composite shows vegetation in various shades of green. \n",
    "# In general, darker shades of green indicate denser vegetation. But brown is indicative of bare soil and built-up areas.\n",
    "\n",
    "# Agriculture (B11, B8, B2)\n",
    "# Sentinel 2 Agriculture\n",
    "# The agriculture band combination uses SWIR-1 (B11), near-infrared (B8), and blue (B2). It’s mostly used to monitor the health of crops because of how it uses short-wave and near-infrared. \n",
    "# Both these bands are particularly good at highlighting dense vegetation that appears as dark green.\n",
    "\n",
    "# Vegetation Index (B8-B4)/(B8+B4)\n",
    "# Sentinel 2 Vegetation Index\n",
    "# Because near-infrared (which vegetation strongly reflects) and red light (which vegetation absorbs), the vegetation index is good for quantifying the amount of vegetation. \n",
    "# The formula for the normalized difference vegetation index is (B8-B4)/(B8+B4). While high values suggest dense canopy, low or negative values indicate urban and water features.\n",
    "\n",
    "# Moisture Index (B8A-B11)/(B8A+B11)\n",
    "# Sentinel 2 Moisture Index\n",
    "# The moisture index is ideal for finding water stress in plants. It uses the short-wave and near-infrared to generate an index of moisture content. \n",
    "# In general, wetter vegetation has higher values. But lower moisture index values suggest plants are under stress from insufficient moisture.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Sentinel 2 - L2A\n",
    "# =============================================================================\n",
    "# Subset number of fields to process\n",
    "k = 500\n",
    "\n",
    "idxStart = 5000\n",
    "idxEnd = 7943\n",
    "\n",
    "ccFields = ccData['features'][idxStart:idxEnd] # To test with\n",
    "\n",
    "# Create a dict of processed fields\n",
    "processedFields = {'ID': []}\n",
    "\n",
    "fieldData = []\n",
    "\n",
    "# Create a list of periods in 2021 and 2022\n",
    "dtPeriods2021 = pd.date_range(start=\"2021-08-01T00:00:00Z\",end=\"2021-11-01T00:00:00Z\", periods = 10).to_pydatetime().tolist()\n",
    "dtPeriods2022 = pd.date_range(start=\"2022-08-01T00:00:00Z\",end=\"2022-11-01T00:00:00Z\", periods = 10).to_pydatetime().tolist()\n",
    "\n",
    "# Create a list of intervals in 2021 and 2022\n",
    "dtIntervals2021 = []\n",
    "dtIntervals2022 = []\n",
    "\n",
    "for y in range(len(dtPeriods2021)-1):\n",
    "    start = dtPeriods2021[y]\n",
    "    end = dtPeriods2021[y+1]\n",
    "    time_interval = start, end\n",
    "    dtIntervals2021.append(time_interval)\n",
    "\n",
    "for y in range(len(dtPeriods2022)-1):\n",
    "    start = dtPeriods2022[y]\n",
    "    end = dtPeriods2022[y+1]\n",
    "    time_interval = start, end\n",
    "    dtIntervals2022.append(time_interval)\n",
    "\n",
    "# Loop over Catch Crop Fields from GeoJSON\n",
    "for i, field in enumerate(ccFields):\n",
    "\n",
    "    # Sets time interval depending on\n",
    "    start_date = str(int(field['properties']['Year'])) + \"-08-01\"\n",
    "    end_date = str(int(field['properties']['Year'])) + \"-11-01\"\n",
    "    time_interval = start_date, end_date\n",
    "\n",
    "    # Converts geometry from GeoJSON to SentinelHub format\n",
    "    geometry = Geometry(field['geometry'], crs=CRS.WGS84)\n",
    "    \n",
    "    # Create a search iterator to find avalable imagery for the field polygon\n",
    "    search_iterator = catalog.search(\n",
    "        DataCollection.SENTINEL2_L2A,\n",
    "        geometry = geometry,\n",
    "        time = time_interval,\n",
    "        fields = {\"include\": [\"id\", \"properties.datetime\", \"properties.eo:cloud_cover\"], \"exclude\": []},\n",
    "        )\n",
    "    \n",
    "    results = list(search_iterator)\n",
    "\n",
    "    if field['properties']['Year'] == 2021:\n",
    "        dtIntervals = dtIntervals2021\n",
    "    elif field['properties']['Year'] == 2022:\n",
    "        dtIntervals = dtIntervals2022\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "\n",
    "    # Sets margin to filter acqusition time to avoid pictures from within the same time_difference\n",
    "    time_difference = dt.timedelta(hours=1)\n",
    "\n",
    "    # Use in case of last image in the last period\n",
    "#    dtIntervals = [dtIntervals[8]]\n",
    "\n",
    "    leastCCDatetimes = []\n",
    "    leastCC = []\n",
    "\n",
    "    for interval in dtIntervals:\n",
    "        intervalResults = [x for x in results if (interval[0] < dt.datetime.fromisoformat(x['properties']['datetime']) < interval[1])]\n",
    "        resultSort = sorted(intervalResults, key=lambda i: (i['properties']['eo:cloud_cover']))\n",
    "        leastCCDatetimes.append(dt.datetime.fromisoformat(resultSort[0]['properties']['datetime']))\n",
    "        leastCC.append(resultSort[0]['properties']['eo:cloud_cover'])\n",
    "\n",
    "    field['properties']['imagePeriod'] = dtIntervals\n",
    "    field['properties']['imageDateTime'] = leastCCDatetimes\n",
    "    field['properties']['imageCloudCover'] = leastCC\n",
    "\n",
    "    process_requests = []\n",
    "\n",
    "    for timeStamp in leastCCDatetimes:\n",
    "        \n",
    "        request = SentinelHubRequest(\n",
    "            evalscript = evalscriptAllBands_L2A,\n",
    "            #evalscript = evalscriptRGB,\n",
    "            input_data = [\n",
    "                SentinelHubRequest.input_data(\n",
    "                    data_collection = DataCollection.SENTINEL2_L2A,\n",
    "                    time_interval = (timeStamp - time_difference, timeStamp + time_difference),\n",
    "                    mosaicking_order = \"leastCC\"\n",
    "                    )\n",
    "                ],\n",
    "            responses = [SentinelHubRequest.output_response(\"default\", MimeType.TIFF)],\n",
    "            geometry = geometry,\n",
    "            config = config,            \n",
    "            )\n",
    "        process_requests.append(request)\n",
    "\n",
    "    client = SentinelHubDownloadClient(config=config)\n",
    "    \n",
    "    download_requests = [request.download_list[0] for request in process_requests]\n",
    "    \n",
    "    data = client.download(download_requests)\n",
    "        \n",
    "    # Inserts images in list \n",
    "    fieldData.append(data)\n",
    "    \n",
    "    # Makes the program wait for X second to avoid download rate limit\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Print run number to \n",
    "    print(f'Index processed: {idxStart + i}')\n",
    "\n",
    "    # Saves images (numpy array) to disk\n",
    "    if (i + 1) % k == 0:\n",
    "        image = np.asarray(fieldData)\n",
    "\n",
    "        print(np.shape(image))\n",
    "\n",
    "        path_to_OutputFile = f'D:/Data/CatchCrop/All/ccImageIndex{idxStart + i + 1 - k}_{idxStart + i}.npy'\n",
    "        \n",
    "        with open(path_to_OutputFile, \"wb\") as fp:\n",
    "            np.save(fp, image, allow_pickle=True, fix_imports=True)\n",
    "\n",
    "        fPath = f'D:/Data/CatchCrop/All/ccFieldsProcessed{idxStart + i + 1 - k}_{idxStart + i}.npy'\n",
    "\n",
    "        with open(fPath, \"w\") as fp:\n",
    "            json.dump(ccFields, fp, default=str)\n",
    "\n",
    "        fieldData = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Print images\n",
    "# =============================================================================\n",
    "\n",
    "fieldImages = fieldData[0:2]\n",
    "\n",
    "for i in range(len(fieldImages)):\n",
    "    data = fieldImages[i]\n",
    "    dTimes = dtIntervals\n",
    "    gt = ccData['features'][i]['properties']['ccLabel']\n",
    "    \n",
    "    ncols, nrows = 3, ceil(9/3)\n",
    "\n",
    "    fig, axis = plt.subplots(\n",
    "        ncols=ncols, nrows = nrows, figsize = (10, 20), subplot_kw = {\"xticks\": [], \"yticks\": [], \"frame_on\": False}\n",
    "        )\n",
    "    \n",
    "    for idx, (image, timeStamp) in enumerate(zip(data, dTimes)):\n",
    "        ax = axis[idx // ncols][idx % ncols]\n",
    "        image = np.asarray(image)\n",
    "        # Change from BGR to RGB\n",
    "        image = np.flip(image[:,:,0:3], axis=-1)\n",
    "        ax.imshow(np.clip(image * 2.5 / 10000, 0, 1))\n",
    "#        ax.set_title(timeStamp.date().isoformat(), fontsize = 10)        \n",
    "        ax.set_title(f\"GroundTruth: {gt}. \\n Time: {timeStamp}.\" , fontsize = 8)\n",
    "        \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hente Datoer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Sentinel 2 - L2A\n",
    "# =============================================================================\n",
    "# Subset number of fields to process\n",
    "k = 500\n",
    "\n",
    "# len(ccFields) noAlt: 4163\n",
    "# # len(ccFields) All: 7935\n",
    "idxStart = 0\n",
    "idxEnd = 7943\n",
    "\n",
    "ccFields = ccData['features'][idxStart:idxEnd] # To test with\n",
    "\n",
    "# Create a dict of processed fields\n",
    "processedFields = {'ID': []}\n",
    "\n",
    "fieldData = []\n",
    "\n",
    "# Create a list of periods in 2021 and 2022\n",
    "dtPeriods2021 = pd.date_range(start=\"2021-08-01T00:00:00Z\",end=\"2021-11-01T00:00:00Z\", periods = 10).to_pydatetime().tolist()\n",
    "dtPeriods2022 = pd.date_range(start=\"2022-08-01T00:00:00Z\",end=\"2022-11-01T00:00:00Z\", periods = 10).to_pydatetime().tolist()\n",
    "\n",
    "# Create a list of intervals in 2021 and 2022\n",
    "dtIntervals2021 = []\n",
    "dtIntervals2022 = []\n",
    "\n",
    "for y in range(len(dtPeriods2021)-1):\n",
    "    start = dtPeriods2021[y]\n",
    "    end = dtPeriods2021[y+1]\n",
    "    time_interval = start, end\n",
    "    dtIntervals2021.append(time_interval)\n",
    "\n",
    "for y in range(len(dtPeriods2022)-1):\n",
    "    start = dtPeriods2022[y]\n",
    "    end = dtPeriods2022[y+1]\n",
    "    time_interval = start, end\n",
    "    dtIntervals2022.append(time_interval)\n",
    "\n",
    "# Loop over Catch Crop Fields from GeoJSON\n",
    "for i, field in enumerate(ccFields):\n",
    "\n",
    "    # Sets time interval depending on\n",
    "    start_date = str(int(field['properties']['Year'])) + \"-08-01\"\n",
    "    end_date = str(int(field['properties']['Year'])) + \"-11-01\"\n",
    "    time_interval = start_date, end_date\n",
    "\n",
    "    # Converts geometry from GeoJSON to SentinelHub format\n",
    "    geometry = Geometry(field['geometry'], crs=CRS.WGS84)\n",
    "    \n",
    "    # Create a search iterator to find avalable imagery for the field polygon\n",
    "    search_iterator = catalog.search(\n",
    "        DataCollection.SENTINEL2_L2A,\n",
    "        geometry = geometry,\n",
    "        time = time_interval,\n",
    "        fields = {\"include\": [\"id\", \"properties.datetime\", \"properties.eo:cloud_cover\"], \"exclude\": []},\n",
    "        )\n",
    "    \n",
    "    results = list(search_iterator)\n",
    "\n",
    "    if field['properties']['Year'] == 2021:\n",
    "        dtIntervals = dtIntervals2021\n",
    "    elif field['properties']['Year'] == 2022:\n",
    "        dtIntervals = dtIntervals2022\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "\n",
    "    # Sets margin to filter acqusition time to avoid pictures from within the same time_difference\n",
    "    time_difference = dt.timedelta(hours=1)\n",
    "\n",
    "    # Use in case of last image in the last period\n",
    "#    dtIntervals = [dtIntervals[8]]\n",
    "\n",
    "    leastCCDatetimes = []\n",
    "    leastCC = []\n",
    "\n",
    "    for interval in dtIntervals:\n",
    "        intervalResults = [x for x in results if (interval[0] < dt.datetime.fromisoformat(x['properties']['datetime']) < interval[1])]\n",
    "        resultSort = sorted(intervalResults, key=lambda i: (i['properties']['eo:cloud_cover']))\n",
    "        leastCCDatetimes.append(dt.datetime.fromisoformat(resultSort[0]['properties']['datetime']))\n",
    "        leastCC.append(resultSort[0]['properties']['eo:cloud_cover'])\n",
    "\n",
    "    field['properties']['imagePeriod'] = dtIntervals\n",
    "    field['properties']['imageDateTime'] = leastCCDatetimes\n",
    "    field['properties']['imageCloudCover'] = leastCC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to GeoJSON\n",
    "# path_to_OutputFile = \"Data/ccInfoGDF.geojson\"\n",
    "path_to_OutputFile = \"C:/Users/morte/OneDrive - Syddansk Universitet/Speciale2023/Data/ccInfoGDFtest.geojson\" # GeoJSON med alle typer efterafgrøder\n",
    "# path_to_OutputFile = \"C:/Users/morte/OneDrive - Syddansk Universitet/Speciale2023/Data/ccNoAltInfoGDFtest.geojson\" # GeoJSON kun med Målrettede Efterafgrøder\n",
    "\n",
    "with open(path_to_OutputFile, \"w\") as fp:\n",
    "    json.dump(ccFields, fp, default=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_OutputFile = \"C:/Users/morte/OneDrive - Syddansk Universitet/Speciale2023/Data/ccFieldsImages.geojson\"\n",
    "\n",
    "# with open(path_to_OutputFile, \"w\") as fp:\n",
    "#     json.dump(ccData, fp)\n",
    "\n",
    "ccGDF = gpd.GeoDataFrame.from_features(ccData[\"features\"])\n",
    "\n",
    "ccGDF.to_file('C:/Users/morte/OneDrive - Syddansk Universitet/Speciale2023/Data/ccFieldsImages.gpkg', driver='GPKG', mode=\"a\")  \n",
    "\n",
    "\n",
    "\n",
    "#ccGDF = gpd.GeoDataFrame.from_features(ccData[\"features\"])\n",
    "\n",
    "#ccGDF.to_parquet('C:/Users/morte/OneDrive - Syddansk Universitet/Speciale2023/Data/ccFieldsImages.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoFile = \"C:/Users/morte/OneDrive - Syddansk Universitet/Speciale2023/Data/ccFieldsImagesCM.gpkg\"\n",
    "\n",
    "test = geoFile[0]['properties']['sentinel2_L2A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = gpd.read_parquet('C:/Users/morte/OneDrive - Syddansk Universitet/Speciale2023/Data/ccFieldsImages.parquet')\n",
    "\n",
    "\n",
    "\n",
    "#data = list(ccData['features'][0]['properties']['sentinel2_L2A'].values())\n",
    "\n",
    "image1 = np.asarray(data[1])\n",
    "\n",
    "image1 = np.flip(image1[:,:,0:3], axis=-1)\n",
    "\n",
    "print(image1)\n",
    "\n",
    "plot_image(image1, factor=3.5 / 10000, vmax=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Print images\n",
    "# =============================================================================\n",
    "\n",
    "# To chance from BGR to RGB\n",
    "#np.flip(data[:,:,1:3], axis=-1) \n",
    "#img = img[:,:,::-1]\n",
    "\n",
    "for i in range(len(df)):\n",
    "    data = list(df[i]['properties']['sentinel2_L2A'].values())\n",
    "    dTimes = list(df[i]['properties']['sentinel2_L2A'].keys())\n",
    "    gt = df[i]['properties']['ccLabel']\n",
    "    \n",
    "    ncols, nrows = 2, ceil(len(dTimes)/2)\n",
    "\n",
    "    fig, axis = plt.subplots(\n",
    "        ncols=ncols, nrows = nrows, figsize = (10, 20), subplot_kw = {\"xticks\": [], \"yticks\": [], \"frame_on\": False}\n",
    "        )\n",
    "    \n",
    "    for idx, (image, timeStamp) in enumerate(zip(data, dTimes)):\n",
    "        ax = axis[idx // ncols][idx % ncols]\n",
    "        image = np.asarray(image)\n",
    "     #   image = image[:,:,1:4]\n",
    "        ax.imshow(np.clip(image * 2.5 / 255, 0, 1))\n",
    "#        ax.set_title(timeStamp.date().isoformat(), fontsize = 10)        \n",
    "        ax.set_title(f\"GroundTruth: {gt}. Time: {timeStamp}.\" , fontsize = 10)\n",
    "        \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Save to disk\n",
    "# =============================================================================\n",
    "\n",
    "# Fejl kan vist løses med liste men det skal vi så også huske npår indlæses...\n",
    "# https://stackoverflow.com/questions/26646362/numpy-array-is-not-json-serializable\n",
    "\n",
    "#b = data[0].tolist()\n",
    "\n",
    "#a_restored = np.asarray(b)\n",
    "\n",
    "print(data[0])\n",
    "\n",
    "path_to_OutputFile = \"Data/ccFieldsImages.geojson\"\n",
    "\n",
    "with open(path_to_OutputFile, \"w\") as fp:\n",
    "    json.dump(ccData, fp)\n",
    "\n",
    "ccGDF = gpd.GeoDataFrame.from_features(ccData[\"features\"])\n",
    "\n",
    "ccGDF.to_file('Data/ccFieldsImages.shp')\n",
    "\n",
    "ccGDF.to_file('Data/ccFieldsImages.gpkg', driver='GPKG')#, mode=\"a\")  \n",
    "\n",
    "geoFile = \"C:/specialeData/ccFieldsImagesCM.gpkg\"\n",
    "\n",
    "ccFields = gpd.read_file(geoFile, driver='GPKG')\n",
    "\n",
    "#gdf.to_file('dataframe.shp', mode=\"a\")  \n",
    "\n",
    "ccGDF.to_feather('Data/ccFieldsImages.feather')\n",
    "\n",
    "df = gpd.read_feather(\"Data/ccFieldsImages.parquet\")  \n",
    "\n",
    "ccGDF.to_parquet('Data/ccFieldsImages.parquet')\n",
    "\n",
    "df = gpd.read_parquet(\"Data/ccFieldsImages.parquet\")\n",
    "\n",
    "# =============================================================================\n",
    "# Tensor\n",
    "# =============================================================================\n",
    "\n",
    "test = {str(dTimes[i]): data[i] for i in range(len(dTimes))}\n",
    "\n",
    "for item in data:    \n",
    "    tensor1 = tf.convert_to_tensor(item)\n",
    "    print(tensor1)\n",
    "\n",
    "tensor1 = tf.convert_to_tensor(data)\n",
    "\n",
    "test = np.stack(data)\n",
    "\n",
    "for i in range(len(data)):\n",
    "    \n",
    "    path = str(\"Data/images/test\"+str(i))\n",
    "    \n",
    "    np.save(path, data[i], allow_pickle=True, fix_imports=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Sentinel 2 - L2A\n",
    "# =============================================================================\n",
    "\n",
    "# Subset number of fields to process\n",
    "ccData['features'] = ccData['features'][0:4000] # To test with\n",
    "\n",
    "#third_list = [field for field in first_list if i['name'] not in second_list]\n",
    "\n",
    "runN = 0\n",
    "\n",
    "# Create a dict of processed fields\n",
    "processedFields = {'ID': []}\n",
    "\n",
    "fieldData = ['']\n",
    "\n",
    "# Loop over Catch Crop Fields from GeoJSON\n",
    "for field in ccData['features']:\n",
    "\n",
    "    print(field['properties']['Year'])\n",
    "\n",
    "\n",
    "    # Converts geometry from GeoJSON to SentinelHub format\n",
    "    geometry = Geometry(field['geometry'], crs=CRS.WGS84)\n",
    "    \n",
    "    # Create a search iterator to find avalable imagery for the field polygon\n",
    "    search_iterator = catalog.search(\n",
    "        DataCollection.SENTINEL2_L2A,\n",
    "        geometry = geometry,\n",
    "        time = time_interval,\n",
    "        fields = {\"include\": [\"id\", \"properties.datetime\", \"properties.eo:cloud_cover\"], \"exclude\": []},\n",
    "        )\n",
    "    \n",
    "    resultsL2A = list(search_iterator)\n",
    "\n",
    "    # Create a search iterator to find avalable imagery for the field polygon\n",
    "    search_iterator = catalog.search(\n",
    "        DataCollection.SENTINEL2_L1C,\n",
    "        geometry = geometry,\n",
    "        time = time_interval,\n",
    "        fields = {\"include\": [\"id\", \"properties.datetime\", \"properties.eo:cloud_cover\"], \"exclude\": []},\n",
    "        )\n",
    "    \n",
    "    resultsL1C = list(search_iterator)\n",
    "\n",
    "\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f94e3f6a2fa8ae583410be7c8dc34c20c9c146b09e59fd517736280eea4dc44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
